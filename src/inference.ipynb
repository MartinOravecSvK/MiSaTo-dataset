{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import h5py \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "sys.path.insert(0, \"../examples\")\n",
    "sys.path.insert(0, \"data/components/\")\n",
    "from QMmodel import GNN_QM\n",
    "from MDmodel import GNN_MD\n",
    "from data.components.transformQM import GNNTransformQM\n",
    "from data.components.transformMD import GNNTransformMD\n",
    "from data.processing.inference_QM import main\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation H5 file from a ligand pdbid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to run inference on a new structure from PDB. It is either possible to provide a already downloaded fileName or to just give the pdbid and it will be downloaded automatically. (If you run the script directly in the terminal just give the keywords in the promt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  pdbid = \"vww\"\n",
    "  fileName = None\n",
    "  datasetOutName = 'inference_for_qm.hdf5'\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading vww.sdf\n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of Ionization potential and Hardness by our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the created h5 file and store the elements and coordinates in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmh5_file = \"inference_for_qm.hdf5\"\n",
    "qm_H5File = h5py.File(qmh5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"x\", \"y\", \"z\", \"element\"]\n",
    "atoms = pd.DataFrame(columns = column_names)\n",
    "\n",
    "prop = qm_H5File[\"vww\"][\"atom_properties\"][\"atom_properties_values\"]\n",
    "atoms[\"x\"] = prop[:,0].astype(np.float32)\n",
    "atoms[\"y\"] = prop[:,1].astype(np.float32)\n",
    "atoms[\"z\"] = prop[:,2].astype(np.float32)\n",
    "        \n",
    "atoms[\"element\"] = np.array([element for element in qm_H5File['vww']['atom_properties']['atoms_names'][:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = {\n",
    "    \"atoms\" : atoms,\n",
    "    \"labels\": 0,\n",
    "    \"bonds\": None, \n",
    "    \"id\": \"vww\"\n",
    "}\n",
    "\n",
    "transform = GNNTransformQM()\n",
    "data_item = transform(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run inference using cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN_QM(\n",
       "  (lin0): Linear(in_features=25, out_features=64, bias=True)\n",
       "  (conv): NNConv(64, 64, aggr=mean, nn=Sequential(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=4096, bias=True)\n",
       "  ))\n",
       "  (gru): GRU(64, 64)\n",
       "  (set2set): Set2Set(64, 128)\n",
       "  (lin1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (lin2): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GNN_QM(data_item.num_features, 64)\n",
    "cpt = torch.load(\"../examples/logs/QM_latest/best_weights_rep0.pt\", map_location=torch.device('cpu'))[\"model_state_dict\"]\n",
    "model.load_state_dict(cpt)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the model\n",
    "y_hat = model(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0480, -0.0375], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating H5 file for a protein-ligand complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.processing.pdb_to_h5 import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  pdbid = \"11gs\"\n",
    "  fileName = None\n",
    "  mapPath = \"data/processing/Maps/\"\n",
    "  mask = \"!@H=\" # no Hydrogens, see https://amberhub.chpc.utah.edu/atom-mask-selection-syntax/\n",
    "  datasetOutName = 'inference_for_qm.hdf5'\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11gs/11gs.pdb was created. Please always use this file for inspection because the coordinates might get translated during amber file generation and thus might vary from the input pdb file.\n",
      "traj pytraj.TrajectoryIterator, 1 frames: \n",
      "Size: 0.000146 (GB)\n",
      "<Topology: 6534 atoms, 416 residues, 2 mols, non-PBC>\n",
      "           \n"
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of adaptability by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdh5_file = \"data/processing/inference_from_pdb.hdf5\"\n",
    "md_H5File = h5py.File(mdh5_file)\n",
    "\n",
    "column_names = [\"x\", \"y\", \"z\", \"element\"]\n",
    "atoms_protein = pd.DataFrame(columns = column_names)\n",
    "\n",
    "\n",
    "\n",
    "cutoff = md_H5File[\"11gs\"][\"molecules_begin_atom_index\"][:][-1]\n",
    "\n",
    "atoms_protein[\"x\"] = md_H5File[\"11gs\"][\"atoms_coordinates_ref\"][:][:cutoff, 0]\n",
    "atoms_protein[\"y\"] = md_H5File[\"11gs\"][\"atoms_coordinates_ref\"][:][:cutoff, 1]\n",
    "atoms_protein[\"z\"] = md_H5File[\"11gs\"][\"atoms_coordinates_ref\"][:][:cutoff, 2]\n",
    "\n",
    "atoms_protein[\"element\"] = md_H5File[\"11gs\"][\"atoms_element\"][:][:cutoff]  \n",
    "\n",
    "item = {}\n",
    "item[\"scores\"] = 0\n",
    "item[\"id\"] = \"11gs\"\n",
    "item[\"atoms_protein\"] = atoms_protein\n",
    "\n",
    "transform = GNNTransformMD()\n",
    "data_item = transform(item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN_MD(\n",
       "  (conv1): GCNConv(11, 64)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): GCNConv(64, 128)\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): GCNConv(128, 256)\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): GCNConv(256, 256)\n",
       "  (bn4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): GCNConv(256, 512)\n",
       "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "model = GNN_MD(data_item.num_features, 64)\n",
    "\n",
    "cpt = torch.load(\"../examples/logs/MD_latest/best_weights_rep0.pt\", map_location=torch.device('cpu'))[\"model_state_dict\"]\n",
    "\n",
    "model.load_state_dict(cpt)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1631])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data_item).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1631, 11], edge_index=[2, 27710], edge_attr=[27710], y=[0], pos=[1631, 3], ids='11gs')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a740140079018068b3444b6d89694224b6cb3b34d8392a5487b58edeeeafee1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
